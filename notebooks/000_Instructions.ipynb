{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AHSI - Azure Hyperscale for Seismic Imaging\n",
    "Epic 5.\tAHSI ALICIA (Azure hyperscaLe seIsmiC Imaging bAtch) \n",
    "\n",
    "Reproducible guide based on these [instructions](https://github.com/slimgroup/Azure2019)\n",
    "\n",
    "##### 1. Use Azure portal to create a resource group and these 2 resources under it:\n",
    " - control_plane_ACR, for example [created via Azure Portal](https://docs.microsoft.com/en-us/azure/container-registry/container-registry-get-started-portal). Use portal \"Access Keys\" blade to note:\n",
    "   - Registry name, eg controlplaneacr\n",
    "   - Login server, e.g. controlplaneacr.azurecr.io\n",
    "   - Username\n",
    "   - password   \n",
    "   These info bits will be used in `010_create_control_plane_docker_image.ipynb` below.  \n",
    "   \n",
    " - an [Azure Ubuntu DSVM](https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/dsvm-ubuntu-intro):  \n",
    "   - open  two ports (named below JupPort1 and JupPort2, .e.g. 9998 and 9999) for Jupyter. See these [instructions](https://github.com/microsoft/AMLSDKRModelsOperationalization#vm-provisioning-and-configuration-via-azure-cli) for details.  \n",
    "   __*Security Note*__: Secure [access](https://docs.microsoft.com/en-us/azure/marketplace/cloud-partner-portal/virtual-machine/cpp-connect-vm#connect-to-a-linux-based-vm) to VMs and to Jupyter notebook servers is paramount, but outside the scope of this tutorial. We use here simple security measures like ssh via login and password using non-standard ports. More secure ways use [ssh keys](https://docs.microsoft.com/en-us/azure/virtual-machines/linux/mac-create-ssh-keys) and [jit](https://docs.microsoft.com/en-us/azure/security-center/security-center-just-in-time). It is highly recommended to address the access security issue before starting an Azure development project.  \n",
    "     \n",
    "   - clone this repo (e.g. in /datadrive01/prj/Azure2019)\n",
    "   - [have](https://docs.docker.com/get-started/) docker [installed](https://docs.docker.com/engine/install/ubuntu/). \n",
    "     - Method 2.a has __no__ other dependencies.  \n",
    "     - Method 2.b requires [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) \n",
    "     \n",
    "  \n",
    "   \n",
    "##### 2. Create running env in either of the two following ways:\n",
    "\n",
    "   2.a Create a conda env \"on the fly\" in a miniconda3 docker image/container. This is the recommended, most repro option.    \n",
    "   First, create file __notebooks/not_shared/base.env__ with this content:\n",
    "```\n",
    "vm_Jupyter_port=8888\n",
    "sibling_docker_env_file=not_shared/sibling_docker.env\n",
    "```\n",
    "   Change as needed:\n",
    "    - __vm_Jupyter_port__ is the Jupyter port opened on the VM as mentioned above\n",
    "    - local directory not_shared for sibling_docker_env_file will be vreated my Makefile as described below. It points to the local host directory that will be mounted inside running env docker container as /workspace  \n",
    "     \n",
    "   Then start Jupyter Notebook server in the running env docker ontainer, either via tmux:    \n",
    "```bash\n",
    "tmux new -s miniconda3_02 'make jupyter-base-env' \n",
    "```\n",
    "   or simply:\n",
    "```bash\n",
    "make jupyter-base-env\n",
    "\n",
    "```  \n",
    "\n",
    "   Jupyter Server started above should then be available at vm_Jupyter_port, e.g.:   \n",
    "   http://[AZURE_DSVM].[AZURE_DSVM_REGION].cloudapp.azure.com:8888/notebooks/notebooks/000_Instructions.ipynb\n",
    "\n",
    "   2.b (Alternative option) Create a conda env based on `azure_devito_conda_dep_file_control_plane.yml` file.\n",
    "\n",
    "  \n",
    "   \n",
    "##### 3. Run `notebooks/010_create_control_plane_docker_image.ipynb` \n",
    "Follow the instructions (editing and Azure sign-in steps required) in  and run it to create the control plane and daks docker images.  \n",
    "  \n",
    "     \n",
    "   \n",
    "__________________________________________________________   \n",
    "__________________________________________________________   \n",
    "__________________________________________________________   \n",
    "   \n",
    "    \n",
    "##### 5. Run the azure_batch_shipyard_devito docker image created above in container\n",
    "Use command below. \n",
    "  Change as needed:\n",
    "  - the port forwarding __-p JupPort2:8888__, e.g. -p 9999:8888.  \n",
    "  - use daks_base_docker_image that has been created in  `020_deployK8sClusterAndDask.ipynb`.  \n",
    "  - use daks_ssh_dir with ssh keys created in `020_deployK8sClusterAndDask.ipynb`\n",
    "  - use the EXTERNAL-IP of the devito-server (LoadBalancer) to run devito in dask in Azure as described below. \n",
    "    \n",
    "    \n",
    "```\n",
    "docker run \\\n",
    " -it \\\n",
    " --rm  \\\n",
    " --name azure_batch_shipyard_devito_container01 \\\n",
    " -v $(pwd):/workspace:rw \\\n",
    " -v /datadrive01/prj/Azure2019/notebooks/./not_shared/azuredevitogatechssh:/root/.ssh:ro \\\n",
    " -v /usr/bin/docker:/usr/bin/docker \\\n",
    " -v /var/run/docker.sock:/var/run/docker.sock \\\n",
    " fwi01acr.azurecr.io/azure_batch_shipyard_devito \\\n",
    " /bin/bash\n",
    " \n",
    "```\n",
    "\n",
    "  \n",
    "   \n",
    "##### 7. Start azure batch shipyard compute pool and run jobs\n",
    "root@491f894856fe:/# cd /workspace/src/AzureBatch/shipyard/config_msft_vnettest/\n",
    "root@491f894856fe:/workspace/src/AzureBatch/shipyard/config_msft_vnettest#\n",
    "\n",
    "\n",
    "root@f57986742e96:/workspace/src/AzureBatch/shipyard/config_gcc# python3 /opt/batch-shipyard/shipyard.py pool add -v&  \n",
    "root@f57986742e96:/workspace/src/AzureBatch/shipyard/config_gcc# python3 /opt/batch-shipyard/shipyard.py jobs add --tail stdout.txt -v&\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 000_Instructions.ipynb to html\n",
      "[NbConvertApp] Writing 281956 bytes to 000_Instructions.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert 000_Instructions.ipynb --to html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 000_Instructions.ipynb to markdown\n",
      "[NbConvertApp] Writing 8055 bytes to 000_Instructions.md\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert 000_Instructions.ipynb --to markdown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
